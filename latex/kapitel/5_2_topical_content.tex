\subsection{Topical Content}
\label{Topical Content}

The STM provides an additional way to integrate covariate effects into the model, apart from prevalence variables that impact topic proportions across documents. To be specific, a categorical variable can be selected as topical content variable. While the prevalence variables influence the propensity of the 15 topics for each document, the content variable now allows for the word distributions for a given topic to vary across documents, according to the content variable level. Note that this is a completely new model, which is why one should not expect the resulting topics to be similar. 

Formally, recall that the word distribution used to eventually pick a word is $\boldsymbol{\beta}_{d,n} := \boldsymbol{\beta}(\boldsymbol{z_{d,n}}, Y_d) \in \mathbb{R}^V$, where $\boldsymbol{z_{d,n}}$ is a (latent) indicator variable determining the word's topic assignation and $Y_{d}$ is the document-level topical content variable with $A$ levels. In the prevalence model, no (document-level) topical content variable is specified, implying $\boldsymbol{\beta}_{d,n} = \boldsymbol{\beta}(\boldsymbol{z_{d,n}})$; since $\boldsymbol{z_{d,n}}$ is a word-level variable, $\boldsymbol{\beta}_{d,n}$ is constant across all documents for a given topic $k$. When specifying a content variable $\boldsymbol{Y}$, however, $\boldsymbol{\beta}_{d,n}$ now varies for each document, according to the level $a \in \{1, ..., A\}$ the content variable takes on for document $d$. That is, the total number of $\boldsymbol{\beta}$-vectors, each one of length $V$, now increases from $K$ to $K \cdot A$.

For our specific case, since the topical content variable needs to be categorical, we choose the variable \textit{party}, being categorical by definition. In doing so, we implicitly posit that for a given topic, an MP's party additionally influences the vocabulary used when tweeting about that specific topic. For instance, this implies that an AfD party member tweets about immigration issues in a different linguistic manner than, say, a green MP. Since for the 2017 election period the German parliament contains members of six parties, $\boldsymbol{Y}$ is now technically a matrix with 10998 rows and six columns,\footnote{Recall that the dimensions of matrix $\boldsymbol{Y}$ are due to dummy encoding of the topical content variable in the \textit{stm} model implementation, whereas for notational simplicity we refer to $\boldsymbol{Y}$ as vector and $Y_d$ as scalar.} yielding a total of $15 \cdot 6 = 90$ $\boldsymbol{\beta}$-vectors.

After fitting the model, we proceed as for the prevelance model, that is, by inspecting top words and identifying topic labels. An additional difficulty, however, is that we do not have clear-cut top words per topic anymore; instead, we now have topic-level top words for each of the 15 topics, party-level top words for each of the six parties, as well as interaction top words for each of the 90 topic-party combinations. The table below presents topic labels for all 15 topics, identified by using the same three-step procedure as for the prevalence model before. As can be seen, five topics are labeled as \textit{miscellaneous}, reflecting the complexity caused by the large number of $\boldsymbol{\beta}$-vectors.

\begin{table}[h!]
	\centering
	\captionsetup{justification=centering,margin=2cm}
	\begin{tabular}{|l|l|}
	\hline
	Topic1  & Right/Nationalist 1  \\ \hline
	Topic2  & Miscellaneous 1      \\ \hline
	Topic3  & Left/Humanitarian    \\ \hline
	Topic4  & Housing       	   \\ \hline
	Topic5  & Innovation           \\ \hline
	Topic6  & Green/Energy         \\ \hline
	Topic7  & Miscellaneous 2      \\ \hline
	Topic8  & Corona               \\ \hline
	Topic9  & Foreign Affairs      \\ \hline
	Topic10 & Election             \\ \hline
	Topic11 & Right/Nationalist 2  \\ \hline
	Topic12 & Miscellaneous 3      \\ \hline
	Topic13 & Miscellaneous 4      \\ \hline
	Topic14 & Twitter/Politics     \\ \hline
	Topic15 & Miscellaneous 5      \\ \hline
	\end{tabular}
	\caption{List of topic labels for STM with topical content variable (party).}
	\label{Tab:labels_content}
\end{table}

The topical content model allows for vocabulary usage to differ across political parties, given a topic. In Figure \ref{fig:t8_vocab_parties} below, we visualize this effect for the Corona topic, contrasting the green party "Bündnis 90/Die Grünen" with the right-wing nationalist party "AfD". The result is very insightful: even for a topic as clear-cut and novel as COVID-19, stark differences in terms of vocabulary usage arise. In particular, the AfD uses language suitable to describe immigration (\textit{migration}, \textit{grenz}) in order to discuss Corona, which very much reflects the unimodality of the party's political orientation (as can also be seen in Figure \ref{fig:quasi_t146_cat} at the end of section \ref{Method of Composition}). The green party, on the other hand, seems to address the topic much more specifically, mentioning key words like \textit{massnahm} or \textit{kind}.

\begin{figure}[h!]
  \centering
  \captionsetup{justification=centering,margin=2cm}
  \includegraphics[scale = 0.5]{../plots/5_2/t8_vocab_parties.pdf}
  \caption{Differences in vocabulary usage across parties for the Corona topic.}
  \label{fig:t8_vocab_parties}
\end{figure}

While this type of visualization is indeed insightful, several concerns regarding the topical content model prevail: first of all, there is no natural candidate for the content variable, which - for labeling and interpretational purposes - should ideally be binary. Our dataset contains very few categorical variables, none of them binary. Furthermore, there is no natural, non-arbitrary way to binarize any of the covariates; for instance, binarizing the variable party into conservative and liberal would misclassify at least one party. Therefore, our choice to use party as content variable is the result of a lack of alternatives, rather than being based on sound statistical or theoretical considerations. This, in turn, is reflected in the difficulties with the labeling: recall that one third of all topics were eventually being labeled as miscellaneous. And while the previous illustration of inter-party differences in vocabulary usage is indeed insightful in terms of topic exploration and visualization, the aforementioned doubts lead us to discard the topical content variable for further analysis. In fact, in the next section we consider a model without any metadata covariates.