\section{Introduction}

The rise in popularity of social media has changed various aspects of private, public, and professional life over the last two decades. From a data-analytical point of view, this has led to an unprecedented increase in the supply of publicly available unstructured (text) data, ready to be analyzed. In fact, unstructured data makes up the lion's share of what is called \textit{big data} (\citealp{gandomi2015beyond}). At the same time, advances in the field of machine learning, particularly in \textit{Natural Language Processing} (NLP), have created numerous new opportunities for the analysis of such large-scale unstructured texts.

A field which has been particularly impacted by the use of social media (and the information extracted from it) is politics. At least since the 2016 Brexit vote and US presidential election, politicians have come to recognize not only that social media presence is ever more important, but also how strong a message their social media behavior can transmit. Among social media networks, Twitter is of particular importance, since it allows for direct communication between politicians and voters - and even more so after the Facebook-Cambridge Analytica data breach in 2018. As a consequence, there has been increasing academic interest in text-based (intra- and inter-)party politics (e.g., \citealp{ceron2017intra, daniel2019static, grimmer2010bayesian, quinlan2018show}). Moreover, unstructured text and the insights generated from it can subsequently be used as input for a broad variety of tasks, ranging from election forecasts (e.g., \citealp{burnap2016140, jungherr2016twitter, tumasjan2010predicting}) to prediction of stock market movements (e.g., \citealp{nisar2018twitter}).

A key challenge in analyzing large amounts of unstructured text is to reduce dimensionality and classify pieces of text: either into previously determined categories (for instance, sentiments), which corresponds to a supervised learning problem; or by trying to discover latent thematic clusters that govern the content of the documents, which is now an instance of unsupervised learning (since the number and labeling of clusters is to be determined). In this paper, we use a mixture of both strategies - an unsupervised \textit{topic model} followed by supervised regression analysis - and apply it to German politics. In particular, we construct a dataset where the text documents consist of Twitter messages by German Members of Parliament (MPs) and which furthermore contains a plenitude of personal MP-level data as well as socioeconomic data on an electoral-district level. Subsequently, we fit a \textit{Structural Topic Model} (STM) to the data to discover latent topics and analyze their relationship with document-level metadata. The focus of this paper lies on statistical and methodological aspects of topic models in general, but especially regarding the relation of topics to metadata, instead of specific (politological) hypothesis testing. Altogether, thus, the contribution of this paper is threefold: first, a broad and widely applicable dataset for future research, particularly in political science; second, a topic analysis of German parliamentarians' Twitter communication; and third, critical discussion of existing and development of new tools for (causal) inference within a topic modeling context.

We find that for most model specifications the majority of topics carry meaning, which can be regarded as a form of retrospective model validation. The fact that these topics are converted from mere word clusters into actually meaningful thematic clusters through manual labeling underlines the importance of human judgment in statistical topic modeling - this is in line with \cite{chang2009reading}, who show that solely focusing on quantitative metrics such as held-out likelihood does not guarantee meaningfulness of the latent space. As for document-level metadata, we discover some relevant associations between topic proportions and document features; particularly for the political parties, these relationships are in line with expectation. For continuous covariates such as unemployment and GDP the high degree of uncertainty induced by the underlying generative process of the STM renders relationships insignificant - though the observed tendencies are consistent across all modeling methodologies. The inclusion of a covariate to further model topical content (beyond its effect on topical prevalence) is found to reduce the meaningfulness of the latent space; furthermore, no natural candidate for the topical content variable exists in our case. Finally, we find that double usage of (prevalence) covariate information does not pose a problem, while double usage of document-level associations induces a substantial degree of overfitting.

The remainder of this paper is organized as follows. Section 2 provides the theoretical foundation of topic modeling, in particular the "component models" of the STM which we use for the major part of our analysis, as well as a brief discussion of inference and parameter estimation. Section 3 describes the data collection process, the data itself, and the data preprocessing necessary for topic modeling. Section 4 discusses model selection, labeling as well as global characteristics of the latent space. In section 5, we include document-level metadata into the analysis, presenting the corresponding theory and results. Section 6 deals with alternative modeling approaches and strategies for causal inference. Finally, section 7 concludes.