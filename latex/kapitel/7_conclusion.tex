\section{Conclusion}
\label{Conclusion}

Nowadays, information from a wide variety of fields is publicly available on social media and various other forms of online appearances. Using techniques such as web scraping, the data - frequently text - is readily obtained. In order to extract the information contained within, a proper analysis of large-scale unstructured text is often a central task. Within this field, topic modeling plays an important role.

In this paper we applied the \textit{Structural Topic Model} (STM) to a large data set of Twitter posts and meta-information associated with members of the German Bundestag. In a first step, examining the estimated proportions of topics provided a concise summary of the predominant themes contained within the tweets. Moreover, associating topic proportions with metadata in a descriptive manner enabled us to explore the topical structure along different dimensions, such as time or membership in a political party. Beyond such explorative analysis, we presented a train-test split framework for the STM, recently developed by \cite{egami2018make}, in order to determine cause-effect relationships between metadata covariates and topics. Extending the traditional topic modeling framework to examine causality between estimated topics and metadata is a challenging task and a current field of research. 

Throughout our analysis we paid particular attention to the statistical assumptions and properties of the STM. While our comparison between the STM and the CTM confirms that metadata does have an influence on the estimated topics, this influence seems to be rather small in general. Nevertheless, we believe that the STM's leveraging of document-specific characteristics results in an estimated topical structure which is more realistic than is the case when employing models that do not incorporate metadata information. This is also reflected by a higher held-out likelihood of the STM when compared to simpler topic models, as shown by \cite{roberts2016model}. 

When the explicit aim is to investigate the association between metadata and topics, aside from potential improvements in model fit, the advantages of the STM are less obvious. As with other topic models, the estimation of such relationships occurs in a separate second step. That is, the STM (and especially its implementation in the R package \textit{stm}) does not directly produce a usable estimate of the relationship between metadata and topics. Instead, the authors of the STM employ the method of composition, implemented through the function \textit{estimateEffect} in the \textit{stm} package, in order to estimate such relations. Within this approach, sampled topic proportions are regressed on metadata covariates using an ordinary least squares (OLS) regression. We demonstrated several shortcomings of this approach and presented possible alternatives. First, when dealing with (sampled) topic proportions, these are restricted to the interval $(0,1)$. Using regression approaches that assume a dependent variable in $(0,1)$, we extended the method of composition within the framework of the STM. Second, mixing of Bayesian and frequentist approaches within the method of composition is theoretically not well-founded; we addressed this problem by explicitly employing a Bayesian regression. We believe that this approach is sound and well interpretable and propose its usage in future analyses. Third, separately modeling topic proportions, as is the case with \textit{estimateEffect}, is a simplification since interdependence among different topics is neglected. We drafted an alternative approach by assessing the estimated covariance structure of prevalence covariates directly; however, this approach needs further refinement.

When examining causal effects beyond explorative purposes, we suggest to perform a train-test split. Conducting both steps on the same data, i.e., the estimation of topics and the subsequent estimation of effects based on these topics, results in a biased estimation of effects. As discussed in section \ref{Causal Inference: Train-test Split}, the STM is well-suited for a train-test framework, since it allows for the inclusion of information contained within metadata of the training set when predicting topic proportions on the test set. This is a clear benefit of the STM, emerging from its more advanced design compared to other topic models such as LDA or CTM.

While recently there have been considerable advancements, topic modeling - like other unsupervised learning methods - still presents an active field of research. This particularly holds for questions regarding causality between metadata and topics but also more generally for their generic relationship within a common modeling framework. For instance, automatic model selection and testing with respect to prevalence covariates is currently infeasible within the STM. Thus, a correct specification of topical prevalence relies on domain knowledge of the user. Furthermore we demonstrated that once the model has been specified there exist different approaches to assess topics and their relation to metadata. Some of these approaches have severe shortcomings and others can be further refined in order to obtain an even more realistic picture. For instance, the direct approach presented in section \ref{Direct assessment} uses MAP estimates of topical prevalence coefficients $\boldsymbol{\Gamma}$; future model implementations should enable sampling from the posterior of $\boldsymbol{\Gamma}$ and thus a fully Bayesian approach. Such a procedure could potentially also be used in order to predict topic proportions \textit{without} conditioning on words (in contrast to the procedure described in section \ref{Causal Inference: Train-test Split}). Moreover, regarding topic-metadata relationships, this paper focused on explorative aspects. Inference concerning the importance of specific document features is left to future research. Finally, alternative model designs could prove to be even more suitable for conducting topic analysis, especially with regards to (causal) inference. Future work is needed to address such concerns and thereby improve the insights generated by topic models.

