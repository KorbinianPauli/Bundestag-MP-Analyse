\section{Conclusion}

Today, information from a wide variety of fields are publicly available on social media and various other forms of online appearances. Using techniques such as web scraping, the data, which in many cases consists of text, is readily obtained. In order to extract the information contained within these data, a proper analysis of large-scale unstructured text is, in many cases, a central task. Within this realm, topic modeling plays an important role.

The objectives when conducting a topic analysis cover a wide range of potential scenarios. Traditionally, topic modeling is used as an unsupervised learning method, where a corpus of text is decomposed into a low-dimensional space of latent topics. The obtained structure can be directly leveraged to conduct various explorative tasks. For instance, examining the estimated proportions of topics is a concise way of summarizing the predominant themes contained within the text. Moreover, relating topic proportions to metadata in a descriptive manner allows for exploring the topical structure with respect to different dimensions, such as time, location or the affiliation with a political party. In many cases, however, researchers might be primarily interested in finding cause-effect relationships between metadata covariates and topics. Extending the traditional topic modeling framework in order to determine such causal links is a challenging task and a current field of research. The main difficulty is that the topical structure is not directly observable, and hence when estimating effects between metadata and topics, it has to be considered that the topical structure has been estimated itself in a previous step.

Building on other topic models such as the DMR, the STM directly incorporates metadata information in order to discover the topical structure. Our comparison between a classical STM with metadata information and the CTM confirms that the metadata clearly has an influence on the estimated topics, which is, however, in general rather small. The STM leverages document-specific characteristics, resulting in an estimated topical structure which is likely to be slightly more realistic than is the case when employing models that do not consider metadata information. This is also reflected by a higher heldout-likelihood of the STM when compared to other models, as shown by \cite{roberts2016model}.

When the explicit aim is to investigate the relationship between metadata and topics, aside from the marginal improvements in accuracy, the advantages of the STM are less clear. After all, the estimation of such relationships occurs in a separate, second step. That is, the STM does not directly produce an appropriate estimate of effects between metadata and topics. While the inclusion of metadata makes the use of the method of composition more plausible, separately modeling topic proportions, as implemented through the function \textit{estimateEffect} in the \textit{stm} package, is a vast simplification, since interdependence among the different topics is neglected. Furthermore, when dealing with (sampled) topic proportions, it has to be considered that these proportions are restricted to the interval $(0,1)$. The absence of such assumptions makes \textit{estimateEffect} a rather heuristic tool, which ideally helps researchers to gain a first impression of topic-metadata relationships. While our extensions to the method of composition should provide a more realistic picture, we have come to the conclusion that these approaches, which directly input the estimated topic proportions, even more so when topics are input separately, are best understood as an explorative tool.

We believe that the correct estimation of (causal) effects between metadata and topics should ideally always involve a train-test split. Conducting both steps on the same data, i.e., the estimation of topics and the subsequent estimation of effects based on these topics, results in a biased estimation of these effects. 