{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdp = \"https://www.fdpbt.de/fraktion/abgeordnete\"\n",
    "source_fdp = requests.get(fdp).text\n",
    "soup_fdp = BeautifulSoup(source_fdp, 'html.parser')\n",
    "\n",
    "cdu = \"https://www.cducsu.de/hier-stellt-die-cducsu-bundestagsfraktion-ihre-abgeordneten-vor\"\n",
    "source_cdu = requests.get(cdu).text\n",
    "soup_cdu = BeautifulSoup(source_cdu, 'html.parser')\n",
    "\n",
    "spd = \"https://www.spdfraktion.de/abgeordnete/alle?wp=19&view=list&old=19\"\n",
    "source_spd = requests.get(spd).text\n",
    "soup_spd = BeautifulSoup(source_spd, 'html.parser')\n",
    "\n",
    "# for Die Linke, one needs to extract the twitter info from each individual MdB website\n",
    "linke_base = \"https://www.linksfraktion.de/fraktion/abgeordnete/\"\n",
    "letters = [['a', 'e'], ['f', 'j'], ['k', 'o'], ['p', 't'], ['u', 'z']]\n",
    "linke_name_bins = []\n",
    "\n",
    "for letter in letters:\n",
    "    extension = f'{letter[0]}-bis-{letter[1]}/' \n",
    "    linke_name_bins.append(linke_base + extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_abg_fdp = soup_fdp.find(class_ = 'person-list').find_all(class_ = 'person-item-wrapper')\n",
    "all_abg_cdu = soup_cdu.find_all(class_ = 'teaser delegates')\n",
    "all_abg_spd = soup_spd.find_all(class_ = 'views-row')\n",
    " \n",
    "all_abg_linke = []\n",
    "for name_bin in linke_name_bins:\n",
    "    source = requests.get(name_bin).text\n",
    "    soup = BeautifulSoup(source, 'html.parser')\n",
    "    for abg in soup.find_all('div', attrs = {'class': 'col-xs-12 col-sm-12 col-md-6 col-lg-6'}):\n",
    "        extension = abg.find('h2').find('a')['href'].lstrip('/fraktion/abgeordnete/')\n",
    "        all_abg_linke.append(linke_base + extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_list = []\n",
    "for abg in all_abg_fdp:\n",
    "    name_field = abg.find(class_ = 'person-name')\n",
    "    funktion = name_field.find('span').text.strip()\n",
    "    name = name_field.text.strip('\\n').strip().strip(funktion).strip('\\n').strip()\n",
    "    twitter = abg.find('a', attrs = {'class': 'tw'}, href = True)\n",
    "    twitter_list.append(\n",
    "        {\n",
    "        'Partei': \"FDP\",\n",
    "        'Name': name,\n",
    "        'Twitter': twitter['href'] if twitter is not None else \"\"\n",
    "            }\n",
    "        )\n",
    "    \n",
    "for abg in all_abg_cdu:\n",
    "    twitter = abg.find(class_ = 'twitter')\n",
    "    twitter_list.append(\n",
    "        {\n",
    "        'Partei': \"CDU/CSU\",\n",
    "        'Name': abg.find('h2').find('span').text.strip(' '),\n",
    "        'Twitter': twitter.find('a', href = True)['href'] if twitter is not None else \"\"\n",
    "            }\n",
    "        )\n",
    "    \n",
    "for abg in all_abg_spd:\n",
    "    twitter = abg.find(class_ = 'ico_twitter')\n",
    "    twitter_list.append(\n",
    "        {\n",
    "        'Partei': \"SPD\",\n",
    "        'Name': abg.find('h3').find('a').get_text().strip(' '),\n",
    "        'Twitter': twitter['href'] if twitter is not None else \"\"\n",
    "            }\n",
    "        )\n",
    "    \n",
    "for abg in all_abg_linke:\n",
    "    abg_source = requests.get(abg).text\n",
    "    abg_soup = BeautifulSoup(abg_source, 'html.parser')\n",
    "    twitter = abg_soup.find('a', text = re.compile('Twitter-Profil'))\n",
    "    twitter_list.append(\n",
    "        {\n",
    "        'Partei': \"Die Linke\",\n",
    "        'Name': abg_soup.find('h1').text.strip(' '),\n",
    "        'Twitter': twitter['href'] if twitter is not None else \"\"\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twitter_df = pd.DataFrame(twitter_list)\n",
    "# twitter_df['twitter'] = twitter_df['twitter'].apply(lambda x: x.lstrip('http://twitter.com/'))\n",
    "# twitter_df['twitter'] = twitter_df['twitter'].apply(lambda x: x.lstrip('https://twitter.com/'))\n",
    "# twitter_df['twitter'] = twitter_df['twitter'].apply(lambda x: x.strip(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('abg_df.pickle', 'rb') as handle:\n",
    "    df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_list = []\n",
    "for name in df['Name']:\n",
    "    interim = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", ' '.join(name.split(',')[::-1])).strip(' ')\n",
    "    interim = re.sub(r'(^\\w{1,6}\\. ?)', r'', interim)\n",
    "    interim = re.sub(r'(^\\w{1,6}\\. ?)', r'', interim)\n",
    "    interim = re.sub(r'(^\\w{1,6}\\. ?)', r'', interim)\n",
    "    interim = re.sub(r'(^\\w{1,6}\\. ?)', r'', interim)\n",
    "    interim = re.sub(r'(^\\w{1,6}\\. ?)', r'', interim)\n",
    "    interim = re.sub(r'(^\\w{1,6}\\. ?)', r'', interim)\n",
    "    interim = re.sub(r'(^\\w{1,6}\\. ?)', r'', interim)\n",
    "    interim = re.sub(r'(^\\w{1,6}\\. ?)', r'', interim)\n",
    "    interim = unidecode.unidecode(interim).strip(' ')\n",
    "    matching_list.append(re.sub(' +', ' ', interim))\n",
    "df['Name_matching'] = matching_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.DataFrame(twitter_list)\n",
    "matching_list_twitter = []\n",
    "for name in twitter_df['Name']:\n",
    "    interim = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", ' '.join(name.split(',')[::-1])).strip(' ')\n",
    "    interim = re.sub(r'(^\\w{1,6}\\. ?)', r'', interim)\n",
    "    interim = re.sub(r'(^\\w{1,6}\\. ?)', r'', interim)\n",
    "    interim = re.sub(r'(^\\w{1,6}\\. ?)', r'', interim)\n",
    "    interim = re.sub(r'(^\\w{1,6}\\. ?)', r'', interim)\n",
    "    interim = re.sub(r'(^\\w{1,6}\\. ?)', r'', interim)\n",
    "    interim = unidecode.unidecode(interim).strip(' ')\n",
    "    matching_list_twitter.append(re.sub(' +', ' ', interim))   \n",
    "twitter_df['Name_matching_control'] = matching_list_twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging dataframes (df and twitter_df)\n",
    "df = pd.merge(df, twitter_df, how = 'left', left_on = 'Name_matching', right_on = 'Name_matching_control', suffixes = ('', '_right'))\n",
    "\n",
    "# feeding Twitter account into \"Soziale Medien\"-dictionary\n",
    "for i in range(len(df)):\n",
    "    if 'Twitter' not in df['Soziale Medien'][i]:\n",
    "        df['Soziale Medien'][i]['Twitter'] = df['Twitter'][i]\n",
    "# dropping columns used for merging only\n",
    "df = df.drop(['Name_matching', 'Partei_right', 'Name_right', 'Twitter', 'Name_matching_control'], axis = 1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('abg_df.pickle', 'wb') as handle:\n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n",
      "95\n",
      "201\n",
      "244\n",
      "251\n",
      "343\n",
      "374\n",
      "411\n",
      "433\n",
      "456\n",
      "607\n",
      "632\n",
      "656\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    if (df['Partei'][i] != df['Partei_right'][i] and df['Partei'][i] in ('SPD', 'Die Linke', 'CDU/CSU', 'FDP')):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Carl-Julius Cronenberg'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Name_matching'][95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Partei</th>\n",
       "      <th>Name</th>\n",
       "      <th>Twitter</th>\n",
       "      <th>Name_matching_control</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Partei, Name, Twitter, Name_matching_control]\n",
       "Index: []"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.loc[twitter_df['Name_matching_control'] == 'Sandra Bubendorfer-Licht']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = twitter_df['Partei'] == 'FDP'\n",
    "# twitter_df['Name_matching'][339]\n",
    "# twitter_df[mask][50:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
