---
title: "4_5"
author: "Patrick Schulze, Simon Wiegrebe"
date: "June 2020"
output:
  pdf_document:
    toc: true
    number_sections: true
  html_document: default
bibliography: bibliography.bib
biblio-style: myabbrvnat
link-citations: yes
linkcolor: blue
header-includes:
  - \usepackage{caption}
  - \usepackage{float}
  - \captionsetup{labelformat=empty}
  - \usepackage{multirow}
  - \usepackage{graphicx}
  - \usepackage{booktabs}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Preparation, include=FALSE}
# ----------------------------------------------------------------------------------------------
# ---------------------------------------- Preparation -----------------------------------------
# ----------------------------------------------------------------------------------------------

# Install and load required packages
os <- Sys.info()[["sysname"]] # Get operating system information
itype <- ifelse(os == "Linux", "source", "binary") # Set corresponding installation type
packages_required <- c(
  "betareg", "ggcorrplot", "grid", "gridExtra", "huge", "knitr", "mvtnorm", 
  "quanteda", "reshape2", "scales", "stm", "stringi", "tidyverse", "tm"
)
not_installed <- packages_required[!packages_required %in%
                                     installed.packages()[, "Package"]]
if (length(not_installed) > 0) {
  lapply(
    not_installed,
    install.packages,
    repos = "http://cran.us.r-project.org",
    dependencies = TRUE,
    type = itype
  )
}
lapply(packages_required, library, character.only = TRUE)

# set working directory
# setwd('C:\\Users\\Simon\\OneDrive\\Uni\\LMU\\SS 2020\\Statistisches Consulting\\Bundestag-MP-Analyse')
# setwd("/Users/patrickschulze/Desktop/Consulting/Bundestag-MP-Analyse")
```

### Topical Content

```{r include=FALSE}
# load data
data <- readRDS("../data/preprocessed_monthly.rds")
colnames_table <- read.csv(file = "../data/topic_monthly_colnames.csv")

data_corpus <- readRDS("../data/prep_monthly.rds")
```

```{r echo=FALSE}
K <- 15
```

```{r echo=FALSE}
# choose covariates and number of topics
covar <- "Partei+ Bundesland + s(t, df = 5) + s(Struktur_4, df = 5) + 
  s(Struktur_22, df = 5) + s(Struktur_42, df = 5) + s(Struktur_54, df = 5)"
content_var <- "Partei"
outcome <- ""

prevalence <- as.formula(paste(outcome, covar, sep = "~"))
content <- as.formula(paste(outcome, content_var, sep = "~"))

# fit model
# mod_cont <- stm::stm(
#   documents = data$documents,
#   vocab = data$vocab,
#   data = data$meta,
#   K = K,
#   prevalence = prevalence,
#   content = content,
#   gamma.prior = 'L1',
#   seed = 123,
#   max.em.its = 200,
#   init.type = "Spectral")
# saveRDS(mod_cont, "./data/mod_cont_monthly.rds")

mod_cont <- readRDS("../data/mod_cont_monthly.rds")
```

The STM provides an additional way to integrate covariate effects into the model, apart from prevalence variables that impact topic proportions across documents. To be specific, a categorical variable can be selected as topical content variable. While the prevalence variables influence the propensity of the $K$ topics for each document, the content variable now allows for the word distributions for a given topic to vary across documents, according to content variable levels. Note that this is a completely new model, which is why one should not expect the resulting topics to be similar. 

Formally, recall that the word distribution used to eventually pick a word is $\beta_{d,n} := \beta(z_{d,n}, Y_d) \in \mathbb{R}^V$, where $z_{d,n}$ is a (latent) indicator variable determining the word's topic assignation and $Y_{d}$ is the document-level topical content variable with $A$ levels. In the prevalence model, no (document-level) topical content variable is specified, implying $\beta_{d,n} = \beta(z_{d,n})$; since $z_{d,n}$ is a word-level variable, $\beta_{d,n}$ is constant across all documents for a given topic $k$. When specifying a content variable $Y$, however, $\beta_{d,n}$ now varies for each document, according to the level $a \in \{1, ..., A\}$ the content variable takes on for document $d$. That is, the total number of $\beta$-vectors, each one of length $V$, now increases from $K$ to $K \times A$.

For our specific case, since the topical content variable needs to be categorical, we choose the variable *party*, being categorical by definition and as it  is arguably the most significant factor in determining topic prevalence. IN doing so, we additionally posit that for a given topic, an MP's party also influences the vocabulary used when tweeting about that specific topic. For instance, this implies that an AfD party member tweets about immigration issues in a different linguistic manner than, say, a green MP. Since for the 2017 election period the German parliament contains members of `r mod_cont$settings$dim$A` parties, $\bf{Y}$ is now a matrix with `r mod_cont$settings$dim$N` rows and `r mod_cont$settings$dim$A` columns, yielding a total of `r K*mod_cont$settings$dim$A` $\beta$-vectors.

After fitting the model, we proceed as for the prevelance model, that is, by inspecting top words and identifying topic labels. An additional difficulty, however, is that we do not have clear-cut top words per topic anymore; instead, we now have topic-level top words for each of the `r K` topics, party-level top words for each of the `r mod_cont$settings$dim$A` parties, as well as interaction top words for each of the `r K*mod_cont$settings$dim$A` topic-party combinations. The table below presents topic labels for all `r K` topics, identified by using the same 3-step procedure as for the prevalence model before. As can be seen, five topics are labeled as *miscellaneous*, reflecting the complexity caused by the large number of $\beta$-vectors.

```{r include=FALSE}
# labeling workflow (for each topic): 

## (1) inspect most frequent words per topic (using different metrics as well as word cloud)
## (2) evaluate most representative documents per topic
## (3) assign label

# first, prepare objects/variables needed for labeling process

## table of MAP topic proportions per document (for all topics)
topic_props <- make.dt(
  mod_cont, 
  data$meta[c("Name", "Partei","Datum", "Bundesland")]) %>% 
  cbind(docname = names(data$documents), .)

## top words per topic (for all topics)
topic_words <- labelTopics(mod_cont, n = 15)

## topic to be evaluated
topic_number <- 1
topic_number_long <- paste0("Topic", topic_number)

## number of top documents to be printed in step (2)
docs_number <- 5

## initialize list with empty labels
## initialize list with empty labels
topic_cont_labels <- list(
  Topic1 = NULL,
  Topic2 = NULL,
  Topic3 = NULL,
  Topic4 = NULL,
  Topic5 = NULL,
  Topic6 = NULL,
  Topic7 = NULL,
  Topic8 = NULL,
  Topic9 = NULL,
  Topic10 = NULL,
  Topic11 = NULL,
  Topic12 = NULL,
  Topic13 = NULL,
  Topic14 = NULL,
  Topic15 = NULL
)

# actual labeling porcess

## (1) inspect most frequent words per topic
topic_words$prob[topic_number,] # 20 most frequent words

## (2) evaluate most representative documents per topic
data_corpus$docname <- paste0(data_corpus$Twitter_Username, "_", data_corpus$Jahr, "_", data_corpus$Monat)

repr_docs <-  topic_props %>%
  arrange(desc(!!as.symbol(topic_number_long))) %>%
  .[1:docs_number, c("Name", "docname", "Datum", "Partei", "Bundesland", topic_number_long)] %>%
  left_join(data_corpus[,c("Tweets_Dokument", "docname")], 
            by = "docname")

substr(repr_docs$Tweets_Dokument[1], 0, 256) # view most representative document
topic_number # topic
scales::percent(repr_docs[topic_number_long][1,1], accuracy = 0.01) # proportion
repr_docs$Name[1] # author/MP
repr_docs$Partei[1] # party
repr_docs$Bundesland[1] # state
repr_docs$Datum[1] # date

## (3) assign label
topic_cont_labels[[topic_number]] <- "right/nationalist"

## (3) assign label
topic_cont_labels <- list(
  Topic1 = "Right/Nationalist 1",
  Topic2 = "Miscellaneous 1",
  Topic3 = "Left/Humanitarian",
  Topic4 = "Housing",
  Topic5 = "Innovation",
  Topic6 = "Green/Energy",
  Topic7 = "Miscellaneous 2",
  Topic8 = "Corona",
  Topic9 = "Foreign Affairs",
  Topic10 = "Election",
  Topic11 = "Right/Nationalist 2",
  Topic12 = "Miscellaneous 3",
  Topic13 = "Miscellaneous 4",
  Topic14 = "Twitter/Politics",
  Topic15 = "Miscellaneous 5"
)

topic_cont_labels %>%
  matrix(dimnames = list(names(topic_cont_labels))) # print w/ topic number
```

```{r echo=FALSE}
topic_number <- 8
```

The topical content model allows for vocabulary usage to differ across political parties, given a topic. In the graph below, we visualize this effect for the `r topic_cont_labels[[topic_number]]` topic, contrasting the green party "Bündnis 90/Die Grünen" with the right-wing nationalist party "AfD". The result is very insightful: even for a topic as clear-cut and novel as COVID-19, stark differences in terms of vocabulary usage arise. In particular, the AfD uses language suitable to describe immigration (*migration*, *grenz*) in order to discuss corona, which very much reflects the unimodality of the party's political orientation. The green party, on the other hand, seems to address the topic much more specifically, mentioning key words like *massnahm* or *kind*.

```{r echo=FALSE}
plot(mod_cont, type = "perspectives", topics = topic_number, covarlevels = c("Bündnis 90/Die Grünen", "AfD"), text.cex = 0.8, plabels = c("B'90/Die Grünen", "AfD"))
```



