---
title: "4_5"
author: "Patrick Schulze, Simon Wiegrebe"
date: "June 2020"
output:
  pdf_document:
    toc: true
    number_sections: true
  html_document: default
bibliography: bibliography.bib
biblio-style: myabbrvnat
link-citations: yes
linkcolor: blue
header-includes:
  - \usepackage{caption}
  - \usepackage{float}
  - \captionsetup{labelformat=empty}
  - \usepackage{multirow}
  - \usepackage{graphicx}
  - \usepackage{booktabs}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Preparation, include=FALSE}
# ----------------------------------------------------------------------------------------------
# ---------------------------------------- Preparation -----------------------------------------
# ----------------------------------------------------------------------------------------------

# Install and load required packages
os <- Sys.info()[["sysname"]] # Get operating system information
itype <- ifelse(os == "Linux", "source", "binary") # Set corresponding installation type
packages_required <- c(
  "betareg", "ggcorrplot", "grid", "gridExtra", "huge", "knitr", "mvtnorm", 
  "quanteda", "reshape2", "scales", "stm", "stmprevalence", "stringi", "tidyverse", "tm"
)
not_installed <- packages_required[!packages_required %in%
                                     installed.packages()[, "Package"]]
if (length(not_installed) > 0) {
  lapply(
    not_installed,
    install.packages,
    repos = "http://cran.us.r-project.org",
    dependencies = TRUE,
    type = itype
  )
}
lapply(packages_required, library, character.only = TRUE)

# set working directory
# setwd('C:\\Users\\Simon\\OneDrive\\Uni\\LMU\\SS 2020\\Statistisches Consulting\\Bundestag-MP-Analyse')
# setwd("/Users/patrickschulze/Desktop/Consulting/Bundestag-MP-Analyse")
```

# Results

## Hyperparameter Search and Model Fitting

## Labelling

## Global-level Topic Analysis

## Covariate-level Topic Analysis

## Content Model

## Train-test Split

```{r include=FALSE}
# load data
data <- readRDS("../data/preprocessed_monthly.rds")
colnames_table <- read.csv(file = "../data/topic_monthly_colnames.csv")

# data_corpus <- readRDS("../data/prep_monthly.rds")
# data_aggregated <- readRDS("../data/preprocessed.rds") # MP-level (non-monthly) data
```

```{r echo=FALSE}
K <- 15
```

```{r echo=FALSE}
# choose covariates and number of topics
covar <- "Partei+ Bundesland + s(t, df = 5) + s(Struktur_4, df = 5) +
  s(Struktur_22, df = 5) + s(Struktur_42, df = 5) + s(Struktur_54, df = 5)"
outcome <- ""
prevalence <- as.formula(paste(outcome, covar, sep = "~"))

# # fit model on training data
# mod_ctm <- stm::stm(
#   documents = data$documents,
#   vocab = data$vocab,
#   data = data$meta,
#   K = K,
#   # prevalence = prevalence,
#   # gamma.prior = 'L1',
#   seed = 123,
#   max.em.its = 300,
#   init.type = "Spectral")
# saveRDS(mod_ctm, "../data/mod_ctm_monthly.rds")

mod_ctm <- readRDS("../data/mod_ctm_monthly.rds")

mod_prev <- readRDS("../data/mod_prev_monthly.rds")

# load topic labels
topic_labels <- list(
  Topic1 = "right/nationalist",
  Topic2 = "miscellaneous_1",
  Topic3 = "green/climate",
  Topic4 = "social/housing",
  Topic5 = "Europe_english",
  Topic6 = "mobility",
  Topic7 = "Europe",
  Topic8 = "corona",
  Topic9 = "left/anti-war",
  Topic10 = "Twitter/politics_1",
  Topic11 = "Twitter/politics_2",
  Topic12 = "miscellaneous_2",
  Topic13 = "Twitter/politics_3",
  Topic14 = "right-wing extremism",
  Topic15 = "social/health"
)

# load list of prevalence covariates
varlist <- c(
  "t", "Partei", "Bundesland", "Struktur_4", "Struktur_22", "Struktur_42", "Struktur_54"
)
# load full names of prevalence covariates
varlist_fullnames <- c(
  "Time", "Party", "Federal State", "Immigrants (%)", "GDP per capita", 
  "Unemployement Rate (%)", "vote share (%)"
)

formula <- 1:15~Partei+ Bundesland + s(t, df = 5) + s(Struktur_4, df = 5) + 
 s(Struktur_22, df = 5) + s(Struktur_42, df = 5) + s(Struktur_54, df = 5)
```

To be addressed:
* metadata for test data is entirely meaningless, does not affect topic proportions at all (given words!!!)
* manipulating covariate values neither
* train/test: once words are given, covariates do not have any further impact: change party for MD (or exclude newData), show: no effect on predicted topic proportions (-> for future research: predict topic proportions based on document covariates only)
* train/test: change formulation, since covariates do not really "generate" topic proportions; don't mention causal inference
* train/test: main point of section: validate model: do topics (and their proportions) make sense?
* additional paragraph for two-step procedure (+ 1 top graph)

## Two-step Approach

To avoid overfitting due to double usage of covariates, we fit a simple CTM without including any covariates in the model estimation and estimate the relationship between topic proportions and covariates in a second, isolated step. That is, we forgo the potential (though limited) gains of joint estimation of the STM in favor of a clear-cut two-step procedure which avoids overfitting.

```{r include=FALSE}
## topic proportions by party
heldout <- make.heldout(
                        documents = data$documents,
                        vocab = data$vocab,
                        N = floor(0.1 * length(data$documents)),
                        proportion = 0.5,
                        seed = 123)

# mod_prev_heldout <- stm::stm(
#                       documents = heldout$documents,
#                       vocab = heldout$vocab,
#                       data = data$meta,
#                       K = K,
#                       prevalence = prevalence,
#                       gamma.prior = 'L1',
#                       seed = 123,
#                       max.em.its = 300,
#                       init.type = "Spectral")
# saveRDS(mod_prev_heldout, "../data/mod_prev_heldout_monthly.rds")
mod_prev_heldout <- readRDS("../data/mod_prev_heldout_monthly.rds")

# mod_ctm_heldout <- stm::stm(
#                       documents = heldout$documents,
#                       vocab = heldout$vocab,
#                       data = data$meta,
#                       K = K,
#                       # prevalence = prevalence,
#                       # gamma.prior = 'L1',
#                       seed = 123,
#                       max.em.its = 300,
#                       init.type = "Spectral")
# saveRDS(mod_ctm_heldout, "../data/mod_ctm_heldout_monthly.rds")
mod_ctm_heldout <- readRDS("../data/mod_ctm_heldout_monthly.rds")

eval.heldout(mod_prev_heldout, heldout$missing)[["expected.heldout"]]
eval.heldout(mod_ctm_heldout, heldout$missing)[["expected.heldout"]]

```

```{r echo=FALSE}
diff_matrix <- mod_prev$theta - mod_ctm$theta
abs_diff_matrix <- abs(diff_matrix)
```

As a first step, we fit the CTM analogously to the original STM (which includes topical prevalence variables), the only difference being that no document-level metadata is used in the estimation of the CTM. In line with the performance results in @roberts2016model, we observe a slightly higher held-out likelihood for the STM (-8.5478) than for the CTM (-8.5492) when holding out a random 50% of the words from a randomly chosen 10% of the documents. As for differences in topic proportions between the two models on a document level, we consider the average topic proportion deviation per document, $\frac{1}{K}\sum_{k=1}^{K}|\theta_{d,k}(STM)-\theta_{d,k}(CTM)|$. The resulting average difference between topic proportions per topic, averaged across all documents, amounts to `r scales::percent(mean(rowMeans(abs_diff_matrix)), accuray = 0.01)`; that is, for an average document, the absolute difference in the proportion of each topic is more than `r scales::percent(mean(rowMeans(abs_diff_matrix)))`, which is considerable given the general scale of topic proportions. However, these differences in topic proportions between STM and CTM appear to cancel each other out across documents: when comparing *global* topic proportions (i.e., topic proportions simply averaged across all documents), the results are very similar, with the average difference per topic only amounting to  `r scales::percent(mean(abs(colMeans(diff_matrix))), accuracy = 0.01)`. Altogether, topic proportions seem to be affected by the topical prevalence covariates on an individual document level, but this effect mostly vanishes if we consider corpus-wide topic proportions.

In the second step, we consider the relationship between topic proportions and covariates for the CTM and compare the resulting relationships with those of the originally fitted STM (which contains prevalence covariates). For comparability, we use the same methodology as in section 4.4: applying the method of composition with a quasibinomial regression of individual topic proportions on covariates. The only difference is that prevalence covariates were not included in the model used to generate topic proportions. Consequently, sampling all (unnormalized) topic proportions jointly via the logistic normal distribution (as in Figure 4.XXX) is not applicable here, as no $\Gamma$-vector is being estimated at all. In the figure below, we visualize the CTM topic proportion of three topic across parties. Comparing the results to the corresponding ones of the STM (Figure 4.XXX), we see a similar pattern for all but the green party and a general shift in scale across all parties when considering the "green/climate" topic. For the "social/housing" topic the average proportions by party show a higher degree of resemblance across models. Finally, for the right/national topic, there is a substantial difference between the two models in terms of the topic proportion of the AfD party. We observe the same similarities and differences between the two models if we use beta regression instead of quasibinomial regression within the method of composition, corroborating our results (see appendix).

[Graph quasi_t134_cont_ctm from ../plots/4_5]


For continuous covariates (see appendix), the comparison of STM and CTM yields very similar results to those of the per-party comparison: for the "green/climate" topic, the trends are not that similar anymore and the scale differs (as above, with higher overall topic proportions according to the CTM). For the "social/housing" topic, on the other hand, the relationship between the covariates and topic proportion does not differ very much, neither in trend nor in scale. 

All in all, the comparison of 
